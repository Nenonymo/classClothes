{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove all mentions of blouse_DF and sunderas before writing to CSV, directly after making dataframe\n",
    "# Another approach is to remove the JSON files of everything not MORIA.... and the MIROA with blouse_DF etc.\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "DATAPATH = \"../../data/Datasets_Enhancy/Annotation/\"\n",
    "IMAGEPATH = \"../../data/Datasets_Enhancy/datasets/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(DATAPATH) if isfile(join(DATAPATH, f))]\n",
    "ret = []\n",
    "for f in onlyfiles:\n",
    "    if (\"MIROA\") in f and not (\"blouse\" in f or \"sudaderas\" in f or \"top_DF\" in f):\n",
    "        ret.append(f)\n",
    "print(ret)\n",
    "frames =[]\n",
    "for i in range(len(ret)):\n",
    "    with open(DATAPATH + ret[i]) as f:\n",
    "        d = json.load(f)\n",
    "        frames.append(pd.json_normalize(d['annotations']))\n",
    "        \n",
    "df = pd.concat(frames)\n",
    "exportDf = df[['image_id', 'segmentation']]\n",
    "#exportDf = exportDf[exportDf[\"image_id\"].str.contains(\"blouse_DF\") == False]\n",
    "#exportDf = exportDf[exportDf[\"image_id\"].str.contains(\"top_DF\") == False]\n",
    "#exportDf = exportDf[exportDf[\"image_id\"].str.contains(\"sudaderas\") == False]\n",
    "\n",
    "\n",
    "\n",
    "deleted = 0\n",
    "changed = 0\n",
    "s = len(exportDf.index)\n",
    "outPut = exportDf.copy()\n",
    "\n",
    "for i in range(s):\n",
    "    id = exportDf.image_id.iloc[i]\n",
    "    path1 = IMAGEPATH + id\n",
    "    path2 = IMAGEPATH + \"dataset/\" + id\n",
    "    relPath1 =  id\n",
    "    relPath2 = \"dataset/\" + id\n",
    "    \n",
    "    if not os.path.isfile(path1):\n",
    "        if not os.path.isfile(path2):\n",
    "            try:\n",
    "                idx = outPut.loc[outPut['image_id'] == id].index[0]\n",
    "                print(\"DROPPED AT idx {} path {}\".format(i, path2))\n",
    "                outPut = outPut.drop(idx, axis = 0)\n",
    "                deleted += 1\n",
    "            except:\n",
    "                print(\"ALREADY DROPPED {}\".format(path2))\n",
    "            \n",
    "newLen = len(outPut.index)\n",
    "for i in range(newLen):\n",
    "    id = outPut.image_id.iloc[i]\n",
    "    if os.path.isfile(IMAGEPATH + \"dataset/\" + id):\n",
    "        outPut.loc[outPut['image_id'] == id, \"image_id\"] = \"dataset/\" + id\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total: {}\".format(s))    \n",
    "print(\"Deleted: {}\".format(deleted))\n",
    "print(\"Edited: {}\".format(changed))\n",
    "#outPut.to_csv(r'./export_data.csv', index = False)\n",
    "outPut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deleted = 0\n",
    "changed = 0\n",
    "s = len(exportDf.index)\n",
    "outPut = exportDf.copy()\n",
    "\n",
    "for i in range(s):\n",
    "    id = exportDf.image_id.iloc[i]\n",
    "    path1 = IMAGEPATH + id\n",
    "    path2 = IMAGEPATH + \"dataset/\" + id\n",
    "    relPath1 =  id\n",
    "    relPath2 = \"dataset/\" + id\n",
    "    \n",
    "    if not os.path.isfile(path1):\n",
    "        if not os.path.isfile(path2):\n",
    "            try:\n",
    "                idx = outPut.loc[outPut['image_id'] == id].index[0]\n",
    "                print(\"DROPPED AT idx {} path {}\".format(i, path2))\n",
    "                outPut = outPut.drop(idx, axis = 0)\n",
    "                deleted += 1\n",
    "            except:\n",
    "                print(\"ALREADY DROPPED {}\".format(path2))\n",
    "            \n",
    "newLen = len(outPut.index)\n",
    "for i in range(newLen):\n",
    "    id = outPut.image_id.iloc[i]\n",
    "    if os.path.isfile(IMAGEPATH + \"dataset/\" + id):\n",
    "        outPut.loc[outPut['image_id'] == id, \"image_id\"] = \"dataset/\" + id\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total: {}\".format(s))    \n",
    "print(\"Deleted: {}\".format(deleted))\n",
    "print(\"Edited: {}\".format(changed))\n",
    "#outPut.to_csv(r'./export_data.csv', index = False)\n",
    "outPut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSVPATH = r\"../../data/csv/export_labels_working.csv\"\n",
    "outPut.to_csv(CSVPATH, index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
